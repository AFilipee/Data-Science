{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSAR Oral Toxicity Dataset - Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ds_functions as ds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, validation_curve\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pd.DataFrame = pd.read_csv('datasets/qsar_oral_toxicity_v2.csv')\n",
    "target = 'IS_TOXIC'\n",
    "original_data = data.copy()\n",
    "\n",
    "y: np.ndarray = data.pop(target).values\n",
    "X: np.ndarray = data.values\n",
    "labels = pd.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \\[No Normalization Needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unbalanced = original_data.copy()\n",
    "\n",
    "target_count = original_data[target].value_counts()\n",
    "min_class = target_count.idxmin()\n",
    "ind_min_class = target_count.index.get_loc(min_class)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "values = {'Original': [target_count.values[ind_min_class], target_count.values[1-ind_min_class]]}\n",
    "\n",
    "df_class_min = original_data[original_data[target] == min_class]\n",
    "df_class_max = original_data[original_data[target] != min_class]\n",
    "\n",
    "df_under = df_class_max.sample(len(df_class_min))\n",
    "values['UnderSample'] = [target_count.values[ind_min_class], len(df_under)]\n",
    "df_over = df_class_min.sample(len(df_class_max), replace=True)\n",
    "values['OverSample'] = [len(df_over), target_count.values[1-ind_min_class]]\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=RANDOM_STATE)\n",
    "y = original_data.pop(target).values\n",
    "X = original_data.values\n",
    "smote_X, smote_y = smote.fit_sample(X, y)\n",
    "smote_target_count = pd.Series(smote_y).value_counts()\n",
    "values['SMOTE'] = [smote_target_count.values[ind_min_class], smote_target_count.values[1-ind_min_class]]\n",
    "\n",
    "over_sampled = pd.concat([df_over,df_class_max])\n",
    "under_sampled = pd.concat([df_under,df_class_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampled Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_boosting(X, y):\n",
    "    print('{', len(X), ',', len(y), '}')\n",
    "    trnX, tstX, trnY, tstY = train_test_split(X, y, train_size=0.7, stratify=y)\n",
    "\n",
    "    n_estimators = [5, 10, 25, 50, 75, 100, 150, 200, 250, 300]\n",
    "    max_depths = [5, 10, 25]\n",
    "    learning_rate = [.1, .3, .5, .7, .9]\n",
    "    best = ('', 0, 0)\n",
    "    last_best = 0\n",
    "    best_tree = None\n",
    "\n",
    "    cols = len(max_depths)\n",
    "    plt.figure()\n",
    "    fig, axs = plt.subplots(1, cols, figsize=(cols*ds.HEIGHT, ds.HEIGHT), squeeze=False)\n",
    "    for k in range(len(max_depths)):\n",
    "        d = max_depths[k]\n",
    "        values = {}\n",
    "        for lr in learning_rate:\n",
    "            yvalues = []\n",
    "            for n in n_estimators:\n",
    "                gb = GradientBoostingClassifier(n_estimators=n, max_depth=d, learning_rate=lr)\n",
    "                gb.fit(trnX, trnY)\n",
    "                prdY = gb.predict(tstX)\n",
    "                yvalues.append(metrics.accuracy_score(tstY, prdY))\n",
    "                if yvalues[-1] > last_best:\n",
    "                    best = (d, lr, n)\n",
    "                    last_best = yvalues[-1]\n",
    "                    best_tree = gb\n",
    "            values[lr] = yvalues\n",
    "        ds.multiple_line_chart(n_estimators, values, ax=axs[0, k], title='Gradient Boorsting with max_depth=%d'%d,\n",
    "                            xlabel='nr estimators', ylabel='accuracy', percentage=True)\n",
    "\n",
    "    plt.show()\n",
    "    print('Best results with depth=%d, learning rate=%1.2f and %d estimators, with accuracy=%1.2f'%(best[0], best[1], best[2], last_best))\n",
    "\n",
    "    prd_trn = best_tree.predict(trnX)\n",
    "    prd_tst = best_tree.predict(tstX)\n",
    "    ds.plot_evaluation_results(pd.unique(y), trnY, prd_trn, tstY, prd_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unbalanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y: np.ndarray = data_unbalanced.pop(target).values\n",
    "X: np.ndarray = data_unbalanced.values\n",
    "labels = pd.unique(y)\n",
    "#gradient_boosting(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Over Sampled Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y: np.ndarray = over_sampled.pop(target).values\n",
    "X: np.ndarray = over_sampled.values\n",
    "labels: np.ndarray = pd.unique(y)\n",
    "#gradient_boosting(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under Sampled Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y: np.ndarray = under_sampled.pop(target).values\n",
    "X: np.ndarray = under_sampled.values\n",
    "labels: np.ndarray = pd.unique(y)\n",
    "#gradient_boosting(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = smote_y\n",
    "X = smote_X\n",
    "labels = pd.unique(y)\n",
    "#gradient_boosting(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
